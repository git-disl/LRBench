{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_validate import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n",
    "# path to dataset\n",
    "args.data = './data'\n",
    "args.arch = 'resnet18'\n",
    "assert args.arch in model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.workers = 4\n",
    "args.epochs = 90\n",
    "args.start_epoch = 0\n",
    "args.batch_size = 128\n",
    "args.lr = 0.1\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 1e-4\n",
    "args.print_freq = 10\n",
    "\n",
    "args.resume = ''\n",
    "args.evaluate = False\n",
    "args.pretrained = False\n",
    "# distributed training\n",
    "args.world_size = -1\n",
    "args.rank = -1\n",
    "args.dist_url = 'tcp://224.66.41.62:23456'\n",
    "args.dist_backend = 'nccl'\n",
    "\n",
    "# random seed\n",
    "args.seed = None\n",
    "\n",
    "args.gpu = 0\n",
    "args.multiprocessing_distributed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    cudnn.deterministic = True\n",
    "    warnings.warn('You have chosen to seed training. '\n",
    "                  'This will turn on the CUDNN deterministic setting, '\n",
    "                  'which can slow down your training considerably! '\n",
    "                  'You may see unexpected behavior when restarting '\n",
    "                  'from checkpoints.')\n",
    "\n",
    "if args.gpu is not None:\n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                  'disable data parallelism.')\n",
    "\n",
    "if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "print(\"distributed: \", args.distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print('ngpus_per_node:', ngpus_per_node)\n",
    "# if args.multiprocessing_distributed:\n",
    "#     # Since we have ngpus_per_node processes per node, the total world_size\n",
    "#     # needs to be adjusted accordingly\n",
    "#     args.world_size = ngpus_per_node * args.world_size\n",
    "#     # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "#     # main_worker process function\n",
    "#     mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "# else:\n",
    "#     # Simply call main_worker function\n",
    "#     main_worker(args.gpu, ngpus_per_node, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu is not None:\n",
    "    print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "\n",
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + gpu\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                            world_size=args.world_size, rank=args.rank)\n",
    "# create model\n",
    "if args.pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "    model = models.__dict__[args.arch](pretrained=True)\n",
    "else:\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "    model = models.__dict__[args.arch]()\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print('using CPU, this will be slow')\n",
    "elif args.distributed:\n",
    "    # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "    # should always set the single device scope, otherwise,\n",
    "    # DistributedDataParallel will use all available devices.\n",
    "    if args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model.cuda(args.gpu)\n",
    "        # When using a single GPU per process and per\n",
    "        # DistributedDataParallel, we need to divide the batch size\n",
    "        # ourselves based on the total number of GPUs we have\n",
    "        args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "        args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "    else:\n",
    "        model.cuda()\n",
    "        # DistributedDataParallel will divide and allocate batch_size to all\n",
    "        # available GPUs if device_ids are not set\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "elif args.gpu is not None:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    model = model.cuda(args.gpu)\n",
    "else:\n",
    "    # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "    if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "        model.features = torch.nn.DataParallel(model.features)\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        if args.gpu is None:\n",
    "            checkpoint = torch.load(args.resume)\n",
    "        else:\n",
    "            # Map model to be loaded to specified single gpu.\n",
    "            loc = 'cuda:{}'.format(args.gpu)\n",
    "            checkpoint = torch.load(args.resume, map_location=loc)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        if args.gpu is not None:\n",
    "            # best_acc1 may be from a checkpoint from a different GPU\n",
    "            best_acc1 = best_acc1.to(args.gpu)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "else:\n",
    "    train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "    num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.evaluate:\n",
    "    print(validate(val_loader, model, criterion, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    if args.distributed:\n",
    "        train_sampler.set_epoch(epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "            and args.rank % ngpus_per_node == 0):\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LRBench.framework.pytorch.utility import update_learning_rate\n",
    "from LRBench.lr.piecewiseLR import piecewiseLR\n",
    "from LRBench.monitor.meters import (\n",
    "    Summary,\n",
    "    AverageMeter,\n",
    "    ProgressMeter\n",
    ")\n",
    "from LRBench.framework.pytorch.utility import (\n",
    "    accuracy\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, args, lrbenchLR=None):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e', store=True)\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f', store=True)\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f', store=True)\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    base_iter = epoch * len(train_loader)\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # LRBench\n",
    "        if lrbenchLR:\n",
    "            cur_iter = base_iter + i\n",
    "            update_learning_rate(optimizer, lrbenchLR.getLR(cur_iter))\n",
    "            print(\"learning rate: \", cur_iter, lrbenchLR.getLR(cur_iter))\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "    return losses, top1, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, top1, top5 = train(train_loader, model, criterion, optimizer, epoch, args,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [v.item() for v in top1.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top1.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
