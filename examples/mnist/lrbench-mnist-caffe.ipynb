{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLR (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "* Set up the Python environment and Data for Caffe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "\n",
    "# import caffe, adding it to `sys.path` if needed. Make suer pycaffe is already built.\n",
    "\n",
    "caffe_root = '/home/yanzhaowu/research/lr_study/caffe-gt/'  # set the root directory of Caffe\n",
    "lrbench_root = '/home/yanzhaowu/research/lr_study/DeepLR/LRBench' # set the root directory of LRBench\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(caffe_root, 'python'))\n",
    "sys.path.insert(0, lrbench_root)\n",
    "import caffe\n",
    "\n",
    "# Setup device\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "# run scripts from caffe root\n",
    "cwd = os.getcwd()\n",
    "# print 'current directory', cwd\n",
    "#  uncomment the following for preparing data\n",
    "#os.chdir(caffe_root)\n",
    "# Download data\n",
    "#!data/cifar-10/get_cifar10.sh\n",
    "# Prepare data\n",
    "#!examples/cifar10/create_cifar10.sh\n",
    "# back to cwd\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Neural Network \n",
    "\n",
    "Typically, two external files define the neural network and corresponding training methods:\n",
    "* the net `prototxt` defines the architecture and path to the train/test data (mnist_train_test.prototxt)\n",
    "* the solver `prototxt` define the learning hyper-parameters (here, we use the python interface of Caffe instead.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Metrics\n",
    "\n",
    "* Utility\n",
    "    1. Accuracy (Top-1, Top-5) # Note for MNIST Top-5 may be 100%\n",
    "    2. Average Confidence (AC)\n",
    "    3. Confidence Variance (CV)\n",
    "    4. Confidence Variance Across Class (CVAC)\n",
    "* Robutness\n",
    "    5. Loss Difference\n",
    "    6. Base LR Scale (1, 0.1, 0.5, 5, 10)\n",
    "* Cost\n",
    "    7. #Iterations\n",
    "    8. #Iterations @ Accuracy Threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experiments\n",
    "\n",
    "Compare different learning rates by setting the `solver`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver Configuration (for writeSolver function)\n",
    "\n",
    "# export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "train_net_path = 'mnist_train_test.prototxt'\n",
    "test_net_path = 'mnist_train_test.prototxt'\n",
    "solver_config_path = 'tmp_mnist_solver.prototxt' # temporary solver file\n",
    "### define solver\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "def generateSolver(LR):\n",
    "    \"\"\"\n",
    "    base_lr: k0\n",
    "    \"\"\"\n",
    "    solver = caffe_pb2.SolverParameter()\n",
    "\n",
    "    # Set the random seed for reproducible experiments\n",
    "    solver.random_seed = 0xCAFFE\n",
    "\n",
    "    # Specify locations\n",
    "    solver.train_net = train_net_path\n",
    "    solver.test_net.append(test_net_path)\n",
    "\n",
    "    # Display the current training status.\n",
    "    solver.display = 100\n",
    "    # Test\n",
    "    solver.test_interval = 500 # test every test_interval iterations\n",
    "    solver.test_iter.append(100) # #iterations for each test\n",
    "    solver.max_iter = 10000\n",
    "    \n",
    "    \n",
    "    # Set momentum (Default)\n",
    "    solver.momentum = 0.9\n",
    "    solver.weight_decay = 5e-4 # Different from CIFAR-10\n",
    "    \n",
    "    # Train on the GPU\n",
    "    solver.solver_mode = caffe_pb2.SolverParameter.GPU\n",
    "\n",
    "    # Snapshot\n",
    "    solver.snapshot = 5000\n",
    "    solver.snapshot_prefix = LR.toString() + '/snapshot/mnist_' # Single Solver\n",
    "    \n",
    "    # LR parameters\n",
    "    solver.type = 'SGD'\n",
    "    \n",
    "    # Using LRBench LRs\n",
    "    policy = 'SET'\n",
    "    solver.lr_policy = 'set'\n",
    "    solver.base_lr = LR.getLR(0)\n",
    "\n",
    "    return solver    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithLR(LR):\n",
    "    lrPolicy = LR.toString()\n",
    "    if not os.path.isdir(lrPolicy):\n",
    "        os.mkdir(lrPolicy)\n",
    "    if not os.path.isdir(lrPolicy + '/snapshot'):\n",
    "        os.mkdir(lrPolicy+'/snapshot')\n",
    "    # Write the solver to a temporary file\n",
    "    with open(os.path.join(lrPolicy, lrPolicy+'_'+solver_config_path), 'w') as f:\n",
    "        f.write(str(generateSolver(LR)))\n",
    "    ### load the solver\n",
    "    solver = None  # avoid two solvers\n",
    "    solver = caffe.get_solver(os.path.join(lrPolicy, lrPolicy+'_'+solver_config_path))\n",
    "\n",
    "    ### train (Parameters)\n",
    "    niter = 10000+1\n",
    "    test_interval = 500\n",
    "    test_iteration = 100\n",
    "    display = 100\n",
    "    nclass = 10\n",
    "    nTestSample = 10000.0\n",
    "    # losses will also be stored in the log\n",
    "    train_loss = zeros(int(np.ceil(niter * 1.0 /display)))\n",
    "    lr = zeros(niter)\n",
    "\n",
    "    test_acc = zeros(int(np.ceil(niter * 1.0 / test_interval)))\n",
    "    test_acc_top5 = zeros(int(np.ceil(niter * 1.0 / test_interval)))\n",
    "    test_loss = zeros(int(np.ceil(niter * 1.0 / test_interval)))\n",
    "    test_average_confidence = zeros(int(np.ceil(niter * 1.0 / test_interval)))\n",
    "    test_confidence_variance = zeros(int(np.ceil(niter * 1.0 / test_interval)))\n",
    "    test_confidence_variance_per_class = zeros(int(np.ceil(niter * 1.0 /test_interval)))\n",
    "\n",
    "    _train_loss = 0\n",
    "    _test_loss = 0\n",
    "\n",
    "    _probability = np.empty((0, nclass))\n",
    "\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    # the major training part\n",
    "    for it in range(niter):\n",
    "        lr[it] = solver.lr\n",
    "        solver.set_learning_rate(LR.getLR(it)) # Set learning rate with 'SET' policy\n",
    "        solver.step(1)  # SGD by Caffe\n",
    "        # store the train loss\n",
    "        _train_loss += solver.net.blobs['loss'].data\n",
    "        if it % display == 0:\n",
    "            # average train loss\n",
    "            train_loss[int(it / display)] = _train_loss / min(it+1, display)\n",
    "            _train_loss = 0\n",
    "\n",
    "        # run a full test every so often\n",
    "        if it % test_interval == 0:\n",
    "            # print 'Iteration', it, 'testing...'\n",
    "            for test_it in range(test_iteration):\n",
    "                solver.test_nets[0].forward()\n",
    "                _test_loss += solver.test_nets[0].blobs['loss'].data\n",
    "                if len(_probability) > 0:\n",
    "                    _probability = np.append(_probability, solver.test_nets[0].blobs['probability'].data, axis=0)\n",
    "                    gt_labels = np.append(gt_labels, solver.test_nets[0].blobs['label'].data, axis=0)\n",
    "                else:\n",
    "                    _probability = solver.test_nets[0].blobs['probability'].data\n",
    "                    gt_labels = solver.test_nets[0].blobs['label'].data\n",
    "            test_loss[it // test_interval] = _test_loss / test_iteration\n",
    "            tmp_confidence = list()\n",
    "            tmp_confidence_top5 = list()\n",
    "            tmp_confidence_per_class = [[] for _ in range(nclass)]\n",
    "            for _i in range(len(_probability)):\n",
    "                if np.argmax(_probability[_i]) == int(gt_labels[_i]):\n",
    "                    tmp_confidence.append(np.max(_probability[_i]))\n",
    "                    tmp_confidence_per_class[int(gt_labels[_i])].append(np.max(_probability[_i]))\n",
    "                if int(gt_labels[_i]) in (-_probability[_i]).argsort()[:5]:\n",
    "                    tmp_confidence_top5.append(_probability[int(gt_labels[_i])])\n",
    "            test_average_confidence[it // test_interval] = np.mean(tmp_confidence)\n",
    "            test_confidence_variance[it // test_interval] = np.std(tmp_confidence)\n",
    "            test_acc[it // test_interval] = len(tmp_confidence) / nTestSample\n",
    "            test_acc_top5[it // test_interval] = len(tmp_confidence_top5) / nTestSample\n",
    "            test_confidence_variance_per_class[it // test_interval] = np.nanstd([np.nanmean(_per_class) for _per_class in tmp_confidence_per_class if _per_class != []])\n",
    "\n",
    "            _test_loss = 0\n",
    "            _accuracy = 0\n",
    "            _accuracy_top5 = 0\n",
    "            _probability = np.empty((0, nclass))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print '### Training Time (s): {}, Final Accuracy: {}'.format(end_time-start_time, test_acc[-1])\n",
    "    return  train_loss, lr, test_acc, test_acc_top5, test_loss, test_average_confidence, test_confidence_variance, test_confidence_variance_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from LRBench.lr.LR import LR\n",
    "\n",
    "# Obtain Learning Rates from Database\n",
    "# Here, just for demo\n",
    "LRs = [LR({'lrPolicy': 'FIX', 'k0': 0.01}), \n",
    "       LR({'lrPolicy': 'EXP', 'k0': 0.01, 'gamma': 0.99994}),\n",
    "       LR({'lrPolicy': 'NSTEP', 'k0': 0.001, 'gamma': 0.1, 'l': [8571, 9286, 10000]}),\n",
    "      ]\n",
    "for p in LRs:\n",
    "    print p.toString()\n",
    "    lr_policy = p.toString()\n",
    "    train_loss, lr, test_acc, test_acc_top5, test_loss, test_average_confidence, test_confidence_variance, test_confidence_variance_per_class = trainWithLR(p)\n",
    "    np.savez(os.path.join(lr_policy, lr_policy + '.npz'),\n",
    "                      train_loss=train_loss,\n",
    "                      learning_rate=lr,\n",
    "                      test_acc = test_acc,\n",
    "                      test_acc_top5=test_acc_top5,\n",
    "                      test_loss = test_loss,\n",
    "                      test_average_confidence = test_average_confidence,\n",
    "                      test_confidence_variance =test_confidence_variance,\n",
    "                      test_confidence_variance_per_class = test_confidence_variance_per_class)"
   ]
  }
 ],
 "metadata": {
  "description": "Define, train, and test the classic LeNet with the Python interface.",
  "example_name": "Learning LeNet",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "priority": 2
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
